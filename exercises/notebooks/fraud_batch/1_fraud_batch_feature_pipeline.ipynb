{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f60c52ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <span style=\"font-width:bold; font-size: 3rem; color:#1EB182;\"><img src=\"../images/icon102.png\" width=\"38px\"></img> **Hopsworks Feature Store** </span><span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 01: Feature Pipeline</span>\n",
    "\n",
    "**Note**: This tutorial does not support Google Colab.\n",
    "\n",
    "This is the first part of the quick start series of tutorials about Hopsworks Feature Store. As part of this first module, you will work with data related to credit card transactions. \n",
    "The objective of this tutorial is to demonstrate how to work with the **Hopworks Feature Store**  for batch data with a goal of training and saving a model that can predict fraudulent transactions. Then try it on retrieved from Feature Store batch data.\n",
    "\n",
    "\n",
    "## üóíÔ∏è This notebook is divided in 3 sections:\n",
    "1. Loading the data and feature engineeing,\n",
    "2. Connect to the Hopsworks Feature Store,\n",
    "3. Create feature groups and upload them to the Feature Store.\n",
    "\n",
    "![tutorial-flow](../images/01_featuregroups.png)\n",
    "\n",
    "First of all you will load the data and do some feature engineering on it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec7724a",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4120a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from features import transactions_fraud, window_aggs\n",
    "\n",
    "# Mute warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010286f1",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üíΩ Loading the Data </span>\n",
    "\n",
    "The data you will use comes from three different CSV files:\n",
    "\n",
    "- `credit_cards.csv`: credit card information such as expiration date and provider.\n",
    "- `transactions.csv`: transaction information such as timestamp, location, and the amount. Importantly, the binary `fraud_label` variable tells us whether a transaction was fraudulent or not.\n",
    "- `profiles.csv`: credit card user information such as birthdate and city of residence.\n",
    "\n",
    "You can conceptualize these CSV files as originating from separate data sources.\n",
    "**All three files have a credit card number column `cc_num` in common, which you can use for joins.**\n",
    "\n",
    "Let's go ahead and load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "491a37b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cc_num</th>\n",
       "      <th>provider</th>\n",
       "      <th>expires</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4796807885357879</td>\n",
       "      <td>visa</td>\n",
       "      <td>05/23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4529266636192966</td>\n",
       "      <td>visa</td>\n",
       "      <td>03/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4922690008243953</td>\n",
       "      <td>visa</td>\n",
       "      <td>02/27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             cc_num provider expires\n",
       "0  4796807885357879     visa   05/23\n",
       "1  4529266636192966     visa   03/22\n",
       "2  4922690008243953     visa   02/27"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file containing credit card data\n",
    "credit_cards_df = pd.read_csv(\n",
    "    \"https://repo.hops.works/master/hopsworks-tutorials/data/card_fraud_data/credit_cards.csv\",\n",
    ")\n",
    "\n",
    "# Display the first 3 rows of the credit_cards_df DataFrame\n",
    "credit_cards_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ed8c4f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>mail</th>\n",
       "      <th>birthdate</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>cc_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Catherine Zimmerman</td>\n",
       "      <td>F</td>\n",
       "      <td>valenciajason@hotmail.com</td>\n",
       "      <td>1988-09-20</td>\n",
       "      <td>Bryn Mawr-Skyway</td>\n",
       "      <td>US</td>\n",
       "      <td>4796807885357879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Michael Williams</td>\n",
       "      <td>M</td>\n",
       "      <td>brettkennedy@yahoo.com</td>\n",
       "      <td>1977-03-01</td>\n",
       "      <td>Gates-North Gates</td>\n",
       "      <td>US</td>\n",
       "      <td>4529266636192966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jessica Krueger</td>\n",
       "      <td>F</td>\n",
       "      <td>marthacruz@hotmail.com</td>\n",
       "      <td>1947-09-10</td>\n",
       "      <td>Greenfield</td>\n",
       "      <td>US</td>\n",
       "      <td>4922690008243953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name sex                       mail  birthdate  \\\n",
       "0  Catherine Zimmerman   F  valenciajason@hotmail.com 1988-09-20   \n",
       "1     Michael Williams   M     brettkennedy@yahoo.com 1977-03-01   \n",
       "2      Jessica Krueger   F     marthacruz@hotmail.com 1947-09-10   \n",
       "\n",
       "                City Country            cc_num  \n",
       "0   Bryn Mawr-Skyway      US  4796807885357879  \n",
       "1  Gates-North Gates      US  4529266636192966  \n",
       "2         Greenfield      US  4922690008243953  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file containing profile data\n",
    "# Parse the \"birthdate\" column as datetime\n",
    "profiles_df = pd.read_csv(\n",
    "    \"https://repo.hops.works/master/hopsworks-tutorials/data/card_fraud_data/profiles.csv\", \n",
    "    parse_dates=[\"birthdate\"],\n",
    ")\n",
    "\n",
    "# Display the first 3 rows of the profiles_df\n",
    "profiles_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2543c511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tid</th>\n",
       "      <th>datetime</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>category</th>\n",
       "      <th>amount</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>fraud_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11df919988c134d97bbff2678eb68e22</td>\n",
       "      <td>2022-01-01 00:00:24</td>\n",
       "      <td>4473593503484549</td>\n",
       "      <td>Health/Beauty</td>\n",
       "      <td>62.95</td>\n",
       "      <td>42.30865</td>\n",
       "      <td>-83.48216</td>\n",
       "      <td>Canton</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dd0b2d6d4266ccd3bf05bc2ea91cf180</td>\n",
       "      <td>2022-01-01 00:00:56</td>\n",
       "      <td>4272465718946864</td>\n",
       "      <td>Grocery</td>\n",
       "      <td>85.45</td>\n",
       "      <td>33.52253</td>\n",
       "      <td>-117.70755</td>\n",
       "      <td>Laguna Niguel</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e627f5d9a9739833bd52d2da51761fc3</td>\n",
       "      <td>2022-01-01 00:02:32</td>\n",
       "      <td>4104216579248948</td>\n",
       "      <td>Domestic Transport</td>\n",
       "      <td>21.63</td>\n",
       "      <td>37.60876</td>\n",
       "      <td>-77.37331</td>\n",
       "      <td>Mechanicsville</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                tid            datetime            cc_num  \\\n",
       "0  11df919988c134d97bbff2678eb68e22 2022-01-01 00:00:24  4473593503484549   \n",
       "1  dd0b2d6d4266ccd3bf05bc2ea91cf180 2022-01-01 00:00:56  4272465718946864   \n",
       "2  e627f5d9a9739833bd52d2da51761fc3 2022-01-01 00:02:32  4104216579248948   \n",
       "\n",
       "             category  amount  latitude  longitude            city country  \\\n",
       "0       Health/Beauty   62.95  42.30865  -83.48216          Canton      US   \n",
       "1             Grocery   85.45  33.52253 -117.70755   Laguna Niguel      US   \n",
       "2  Domestic Transport   21.63  37.60876  -77.37331  Mechanicsville      US   \n",
       "\n",
       "   fraud_label  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file containing transaction data\n",
    "# Parse the \"datetime\" column as datetime\n",
    "trans_df = pd.read_csv(\n",
    "    \"https://repo.hops.works/master/hopsworks-tutorials/data/card_fraud_data/transactions.csv\", \n",
    "    parse_dates=[\"datetime\"],\n",
    ")\n",
    "\n",
    "# Display the first 3 rows of the trans_df\n",
    "trans_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717f9102",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16357302",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üõ†Ô∏è Feature Engineering </span>\n",
    "\n",
    "Fraudulent transactions can differ from regular ones in many different ways. Typical red flags would for instance be a large transaction volume/frequency in the span of a few hours. It could also be the case that elderly people in particular are targeted by fraudsters. To facilitate model learning you will create additional features based on these patterns. In particular, you will create two types of features:\n",
    "1. **Features that aggregate data from different data sources**. This could for instance be the age of a customer at the time of a transaction, which combines the `birthdate` feature from `profiles.csv` with the `datetime` feature from `transactions.csv`.\n",
    "2. **Features that aggregate data from multiple time steps**. An example of this could be the transaction frequency of a credit card in the span of a few hours, which is computed using a window function.\n",
    "\n",
    "Let's start with the first category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b919bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_at_transaction</th>\n",
       "      <th>days_until_card_expires</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97.578083</td>\n",
       "      <td>1460.999722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.775344</td>\n",
       "      <td>1733.999352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80.953429</td>\n",
       "      <td>242.998241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age_at_transaction  days_until_card_expires\n",
       "0           97.578083              1460.999722\n",
       "1           33.775344              1733.999352\n",
       "2           80.953429               242.998241"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute age at transaction.\n",
    "trans_df = transactions_fraud.get_age_at_transaction(\n",
    "    trans_df, \n",
    "    profiles_df,\n",
    ")\n",
    "\n",
    "# Compute days until card expires.\n",
    "trans_df = transactions_fraud.get_days_until_card_expires(\n",
    "    trans_df, \n",
    "    credit_cards_df,\n",
    ")\n",
    "\n",
    "# Display the first 3 rows\n",
    "trans_df[[\"age_at_transaction\", \"days_until_card_expires\"]].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d6fd9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate rows in the trans_df DataFrame based on the \"datetime\" column\n",
    "trans_df = trans_df.drop_duplicates([\"datetime\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92820fab",
   "metadata": {},
   "source": [
    "Next, you will create features that for each credit card aggregate data from multiple time steps.\n",
    "\n",
    "Yoy will start by computing the distance between consecutive transactions, lets call it `loc_delta`.\n",
    "Here you will use the [Haversine distance](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.haversine_distances.html?highlight=haversine#sklearn.metrics.pairwise.haversine_distances) to quantify the distance between two longitude and latitude coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47116f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the trans_df DataFrame based on the \"datetime\" column in ascending order\n",
    "trans_df.sort_values(\"datetime\", inplace=True)\n",
    "\n",
    "# Apply the radians function to the \"longitude\" and \"latitude\" columns in the trans_df DataFrame\n",
    "# This is a common preprocessing step for geographical data\n",
    "trans_df[[\"longitude\", \"latitude\"]] = trans_df[[\"longitude\", \"latitude\"]].applymap(radians)\n",
    "\n",
    "# Create a new column \"loc_delta\" in trans_df representing the haversine distance between consecutive transactions for each credit card\n",
    "trans_df[\"loc_delta\"] = trans_df.groupby(\"cc_num\")\\\n",
    "    .apply(lambda x: transactions_fraud.haversine(x[\"longitude\"], x[\"latitude\"]))\\\n",
    "    .reset_index(level=0, drop=True)\\\n",
    "    .fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3abcfc",
   "metadata": {},
   "source": [
    "Next lets compute windowed aggregates. Here you will use 4-hour windows, but feel free to experiment with different window lengths by setting `window_len` below to a value of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9bf9dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_volume_mstd</th>\n",
       "      <th>trans_volume_mavg</th>\n",
       "      <th>trans_freq</th>\n",
       "      <th>loc_delta_mavg</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106015</th>\n",
       "      <td>0.0</td>\n",
       "      <td>73.08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.045635</td>\n",
       "      <td>4032019521897961</td>\n",
       "      <td>2022-03-24 10:57:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106016</th>\n",
       "      <td>0.0</td>\n",
       "      <td>287.33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.045846</td>\n",
       "      <td>4032019521897961</td>\n",
       "      <td>2022-03-28 11:57:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>53.88</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>4032019521897961</td>\n",
       "      <td>2022-04-01 12:57:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106018</th>\n",
       "      <td>0.0</td>\n",
       "      <td>279.73</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.045928</td>\n",
       "      <td>4032019521897961</td>\n",
       "      <td>2022-04-05 13:57:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106019</th>\n",
       "      <td>0.0</td>\n",
       "      <td>73.66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.045974</td>\n",
       "      <td>4032019521897961</td>\n",
       "      <td>2022-04-09 14:57:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        trans_volume_mstd  trans_volume_mavg  trans_freq  loc_delta_mavg  \\\n",
       "106015                0.0              73.08         1.0        0.045635   \n",
       "106016                0.0             287.33         1.0        0.045846   \n",
       "106017                0.0              53.88         1.0        0.000120   \n",
       "106018                0.0             279.73         1.0        0.045928   \n",
       "106019                0.0              73.66         1.0        0.045974   \n",
       "\n",
       "                  cc_num            datetime  \n",
       "106015  4032019521897961 2022-03-24 10:57:02  \n",
       "106016  4032019521897961 2022-03-28 11:57:02  \n",
       "106017  4032019521897961 2022-04-01 12:57:02  \n",
       "106018  4032019521897961 2022-04-05 13:57:02  \n",
       "106019  4032019521897961 2022-04-09 14:57:02  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the window length as \"4h\" (4 hours)\n",
    "window_len = \"4h\"\n",
    "\n",
    "# Use the window_aggs.get_window_aggs_df function to calculate aggregated features for each window in trans_df\n",
    "window_aggs_df = window_aggs.get_window_aggs_df(window_len, trans_df)\n",
    "\n",
    "# Display the last few rows of the resulting window_aggs_df DataFrame to inspect the aggregated features\n",
    "window_aggs_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3021fa4",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">‚öôÔ∏è Convert date time object to unix epoch in milliseconds </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "837bafd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the \"datetime\" values in the trans_df DataFrame to microseconds since the epoch\n",
    "trans_df.datetime = trans_df.datetime.values.astype(np.int64) // 10 ** 6\n",
    "\n",
    "# Convert the \"datetime\" values in the window_aggs_df DataFrame to microseconds since the epoch\n",
    "window_aggs_df.datetime = window_aggs_df.datetime.values.astype(np.int64) // 10 ** 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3df26a9",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">üëÆüèª‚Äç‚ôÇÔ∏è Great Expectations </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9391579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as ge\n",
    "from great_expectations.core import ExpectationSuite, ExpectationConfiguration\n",
    "\n",
    "# Convert the 'trans_df' DataFrame to a Great Expectations DataFrame\n",
    "ge_trans_df = ge.from_pandas(trans_df)\n",
    "\n",
    "# Retrieve the expectation suite associated with the ge DataFrame\n",
    "expectation_suite_transactions = ge_trans_df.get_expectation_suite()\n",
    "\n",
    "# Set the expectation suite name to \"transactions_suite\"\n",
    "expectation_suite_transactions.expectation_suite_name = \"transactions_suite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8969ff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check binary fraud_label column to be in set [0,1]\n",
    "expectation_suite_transactions.add_expectation(\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_distinct_values_to_be_in_set\",\n",
    "        kwargs={\n",
    "            \"column\": \"fraud_label\",\n",
    "            \"value_set\": [0, 1],\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "# Check amount column to be not negative\n",
    "expectation_suite_transactions.add_expectation(\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_between\",\n",
    "        kwargs={\n",
    "            \"column\": \"amount\",\n",
    "            \"min_value\": 0.0,\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "# Loop through specified columns ('tid', 'datetime', 'cc_num') and add expectations for null values\n",
    "for column in ['tid', 'datetime', 'cc_num']:\n",
    "    expectation_suite_transactions.add_expectation(\n",
    "        ExpectationConfiguration(\n",
    "            expectation_type=\"expect_column_values_to_be_null\",\n",
    "            kwargs={\n",
    "                \"column\": column,\n",
    "                \"mostly\": 0.0,\n",
    "            }\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf03efd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c069f5a",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üì° Connecting to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac32437d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <span style=\"color:#ff5f27;\"> ü™Ñ Creating Feature Groups </span>\n",
    "\n",
    "A [feature group](https://docs.hopsworks.ai/3.0/concepts/fs/feature_group/fg_overview/) can be seen as a collection of conceptually related features. In this case, you will create a feature group for the transaction data and a feature group for the windowed aggregations on the transaction data. Both will have `cc_num` as primary key, which will allow you to join them when creating a dataset in the next tutorial.\n",
    "\n",
    "Feature groups can also be used to define a namespace for features. For instance, in a real-life setting you would likely want to experiment with different window lengths. In that case, you can create feature groups with identical schema for each window length. \n",
    "\n",
    "Before you can create a feature group you need to connect to Hopsworks feature store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "287491fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy your Api Key (first register/login): https://c.app.hopsworks.ai/account/api/generated\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Paste it here:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/569493\n",
      "2024-08-28 20:26:27,092 WARNING: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "\n",
      "2024-08-28 20:26:27,095 WARNING: using legacy validation callback\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b61089",
   "metadata": {},
   "source": [
    "To create a feature group you need to give it a name and specify a primary key. It is also good to provide a description of the contents of the feature group and a version number, if it is not defined it will automatically be incremented to `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58353322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get or create the 'transactions_fraud_batch_fg' feature group\n",
    "trans_fg = fs.get_or_create_feature_group(\n",
    "    name=\"transactions_fraud_batch_fg\",\n",
    "    version=1,\n",
    "    description=\"Transaction data\",\n",
    "    primary_key=[\"cc_num\"],\n",
    "    event_time=\"datetime\",\n",
    "    expectation_suite=expectation_suite_transactions,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832333fa",
   "metadata": {},
   "source": [
    "A full list of arguments can be found in the [documentation](https://docs.hopsworks.ai/feature-store-api/latest/generated/api/feature_store_api/#create_feature_group).\n",
    "\n",
    "At this point, you have only specified some metadata for the feature group. It does not store any data or even have a schema defined for the data. To make the feature group persistent you need to populate it with its associated data using the `insert` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f82e4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-28 20:27:07,632 INFO: \t5 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/569493/fs/565316/fg/1143114\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efec4c5e0f114493a50152323ed0cc3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/105092 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: transactions_fraud_batch_fg_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/569493/jobs/named/transactions_fraud_batch_fg_1_offline_fg_materialization/executions\n",
      "‚úÖ Done!\n"
     ]
    }
   ],
   "source": [
    "# Insert data into feature group\n",
    "trans_fg.insert(trans_df)\n",
    "print('‚úÖ Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c6832a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update feature descriptions\n",
    "feature_descriptions = [\n",
    "    {\"name\": \"tid\", \"description\": \"Transaction id\"},\n",
    "    {\"name\": \"datetime\", \"description\": \"Transaction time\"},\n",
    "    {\"name\": \"cc_num\", \"description\": \"Number of the credit card performing the transaction\"},\n",
    "    {\"name\": \"category\", \"description\": \"Expense category\"},\n",
    "    {\"name\": \"amount\", \"description\": \"Dollar amount of the transaction\"},\n",
    "    {\"name\": \"latitude\", \"description\": \"Transaction location latitude\"},\n",
    "    {\"name\": \"longitude\", \"description\": \"Transaction location longitude\"},\n",
    "    {\"name\": \"city\", \"description\": \"City in which the transaction was made\"},\n",
    "    {\"name\": \"country\", \"description\": \"Country in which the transaction was made\"},\n",
    "    {\"name\": \"fraud_label\", \"description\": \"Whether the transaction was fraudulent or not\"},\n",
    "    {\"name\": \"age_at_transaction\", \"description\": \"Age of the card holder when the transaction was made\"},\n",
    "    {\"name\": \"days_until_card_expires\", \"description\": \"Card validity days left when the transaction was made\"},\n",
    "    {\"name\": \"loc_delta\", \"description\": \"Haversine distance between this transaction location and the previous transaction location from the same card\"},\n",
    "]\n",
    "\n",
    "for desc in feature_descriptions: \n",
    "    trans_fg.update_feature_description(desc[\"name\"], desc[\"description\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f7e30a",
   "metadata": {},
   "source": [
    "At the creation of the feature group, you will be prompted with an URL that will directly link to it; there you will be able to explore some of the aspects of your newly created feature group.\n",
    "\n",
    "[//]: <> (insert GIF here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1250c3ce",
   "metadata": {},
   "source": [
    "You can move on and do the same thing for the feature group with our windows aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b8ef9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get or create the 'transactions' feature group with specified window aggregations\n",
    "window_aggs_fg = fs.get_or_create_feature_group(\n",
    "    name=f\"transactions_{window_len}_aggs_fraud_batch_fg\",\n",
    "    version=1,\n",
    "    description=f\"Aggregate transaction data over {window_len} windows.\",\n",
    "    primary_key=[\"cc_num\"],\n",
    "    event_time=\"datetime\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1970657b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/569493/fs/565316/fg/1142101\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8b2069f80f454a9e9d2fb3bad4cde2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/105092 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: transactions_4h_aggs_fraud_batch_fg_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/569493/jobs/named/transactions_4h_aggs_fraud_batch_fg_1_offline_fg_materialization/executions\n",
      "‚úÖ Done!\n"
     ]
    }
   ],
   "source": [
    "# Insert data into feature group\n",
    "window_aggs_fg.insert(window_aggs_df)\n",
    "print('‚úÖ Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68b0c84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update feature descriptions\n",
    "feature_descriptions = [\n",
    "    {\"name\": \"datetime\", \"description\": \"Transaction time\"},\n",
    "    {\"name\": \"cc_num\", \"description\": \"Number of the credit card performing the transaction\"},\n",
    "    {\"name\": \"loc_delta_mavg\", \"description\": \"Moving average of location difference between consecutive transactions from the same card\"},\n",
    "    {\"name\": \"trans_freq\", \"description\": \"Moving average of transaction frequency from the same card\"},\n",
    "    {\"name\": \"trans_volume_mavg\", \"description\": \"Moving average of transaction volume from the same card\"},\n",
    "    {\"name\": \"trans_volume_mstd\", \"description\": \"Moving standard deviation of transaction volume from the same card\"},\n",
    "]\n",
    "\n",
    "for desc in feature_descriptions: \n",
    "    window_aggs_fg.update_feature_description(desc[\"name\"], desc[\"description\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22dce87",
   "metadata": {},
   "source": [
    "Both feature groups are now accessible and searchable in the UI\n",
    "\n",
    "![fg-overview](../images/fg_overview.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8b5d8a",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">‚è≠Ô∏è **Next:** Part 02: Training Pipeline\n",
    " </span> \n",
    "\n",
    "In the following notebook you will use your feature groups to create a dataset you can train a model on.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e1ddeae6eefc765c17da80d38ea59b893ab18c0c0904077a035ef84cfe367f83"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
