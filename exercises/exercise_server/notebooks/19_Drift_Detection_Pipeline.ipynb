{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80d7c61c",
   "metadata": {},
   "source": [
    "# Drift Calculation Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6784ff",
   "metadata": {},
   "source": [
    "In dieser Übung bauen wir eine Streaming Pipeline, welche Mushroom Inferenz-Daten auf Drift prüft und regelmässig die Resultate an unsere Monitoring Infrastruktur meldet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b9ceb9",
   "metadata": {},
   "source": [
    "# Vorbereitung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020387a7",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640cc657",
   "metadata": {},
   "source": [
    "# Übungen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9067cb8",
   "metadata": {},
   "source": [
    "## Architektur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8aa78c3",
   "metadata": {},
   "source": [
    "Unsere Architektur sieht nun wie folgt aus. Neben allen Infrastrukturkomponenten haben wir drei Pipelines:\n",
    " * Unsere Batch Inference Pipeline, welche periodisch getriggert werden muss\n",
    " * Unsere Streaming Inference Pipeline, welche konstant läuft\n",
    " \n",
    "Neu hinzu kommt \n",
    "  * Unsere Streaming Drift Detection Pipeline, welche konstant läuft\n",
    "  \n",
    "und den Datendrift unserer Mushroom Rohdaten an unsere Monitoring-Infrastruktur meldet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb1cdf2",
   "metadata": {},
   "source": [
    "![drift_pipeline_01.png](drift_pipeline_01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1814e826",
   "metadata": {},
   "source": [
    "## Aufbau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562d60e0",
   "metadata": {},
   "source": [
    "* Unser Datagen simuliert Prediction Request Events und schickt entsprechende Event Notifications an Kafka\n",
    "* In diesen Nachrichten sind die Features eines Prediction Requests (bzw. die Rohdaten, da wir in unserem vereinfachten Modell keine Features berechnen) enthalten\n",
    "* Die Drift Detection Pipeline liest diese Notifications laufend von Kafka und sammelt alle Requests, bis sie eine akzeptable Menge zusammen hat\n",
    "* Sie vergleicht dann die aktuellen, von Kafka erhaltenen Daten mit dem Referenzdatenset, welches für das Training des Mushroom-Modells verwendet wurde, und berechnet pro Spalte eine Kennzahl, welche den Drift angibt\n",
    "* Diese Kennzahlen sendet die Pipeline an Statsd, wo sie von Prometheus gepollt werden, welcher die Daten als Zeitreihe speichert\n",
    "* Am Ende der Kette pollt Grafana diese Daten von Prometheus, um sie in einem Dashboard darstellen zu können, um bei zu grossem Drift Alarm zu schlagen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4661397",
   "metadata": {},
   "source": [
    "![drift_pipeline_02.png](drift_pipeline_02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a66be3",
   "metadata": {},
   "source": [
    "## Evidently"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94447711",
   "metadata": {},
   "source": [
    "Für den Vergleich zweier Verteilungen und die Berechnung des Drifts verwenden wir die Bibliothek [Evidently OSS](https://www.evidentlyai.com/evidently-oss). Evidently ist ein Produkt, welches sehr viele Möglichkeiten bietet, um verschiedene Arten von Drift zu berechnen und zu visualisieren. Wir verwenden hier nur einen ganz kleinen Teil davon, nämlich die automatische Berechnung von zwei Distanzmassen (normierte Wasserstein Distanz und normierte Jensen-Shannon Distanz), welche eine Aussage erlauben über die Abweichung zweier Verteilungen voneinander.\n",
    "\n",
    "Evidently beinhaltet eine Logik, um zu entscheiden, welches Distanzmass sich für ein gegebenes Datenset am besten eignet. Für unser Mushroom Datenset hat sich Evidently für die oben genannten Metriken entschieden. Wie dieser Entscheidungsprozess funktioniert, ist [hier](https://www.evidentlyai.com/blog/data-drift-detection-large-datasets) dokumentiert. Wir gehen im Rahmen des Kurses nicht weiter auf diese Wahl ein.\n",
    "\n",
    "Es ist jedoch hilfreich, wenn du dich in die [Core Concepts](https://docs.evidentlyai.com/readme/core-concepts) von Evidently kurz einliest. Die *Test* Funktionalität von Evidently verwenden wir im Workshop nicht, diesen Teil kannst du auslassen. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cf0d56",
   "metadata": {},
   "source": [
    "Schreibe eine Funktion, welche als Argumente zwei Pandas DataFrames erhält. Der eine ist unser Referenz-Datenset (also unsere Trainingsdaten, ohne Label). Der andere entspricht den gesammelten Inferenz-Requests, repräsentiert also aktuelle, neue Daten.\n",
    "\n",
    "Dann machen wir es uns einfach und führen den einen Evidently Report aus mit dem `DataDriftPreset`. Dies generiert den gesamten Report inklusive Visualisierung, aus welchem wir aber nur den Namen des durchgeführten Testes (*stattest_name*) sowie die eigentliche *drift_score* pro Spalte benötigen. Dies ist sicher nicht ein sehr effizientes Vorgehen, da viel generiert wird, was wir gar nicht benötigen. Du kannst gerne selbständig weiter optimieren :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5b2dad",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataDriftPreset\n",
    "from evidently import ColumnMapping\n",
    "from loguru import logger\n",
    "\n",
    "\n",
    "def calculate_drift(df: pd.DataFrame, reference_df: pd.DataFrame,) -> tuple[tuple[str], tuple[float]]:\n",
    "\n",
    "    logger.info(f\"Received window of length {len(df)}\")\n",
    "    \n",
    "    # the dataframe generated from json has an index of dtype str, which we replace by an index of ints,\n",
    "    # or else evidently chokes\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # use a column mapping to make it easy for evidently to find the right metric\n",
    "    column_mapping = ColumnMapping()\n",
    "    column_mapping.categorical_features = ['cap-shape', 'gill-attachment', 'gill-color', 'stem-color']\n",
    "    column_mapping.numerical_features = [c for c in df.columns if c not in column_mapping.categorical_features]\n",
    "\n",
    "    # define and execute evidently standard drift report (don't forget to pass the column mapping)\n",
    "    # your code goes here\n",
    "    \n",
    "    # extract an iterable of features and a dict containing stattest_name and drift_score per column\n",
    "    # one entry of the dict should look like this:\n",
    "    # {'cap-diameter': {'drift_score': 0.1, 'stattest_name': 'Jensen-Shannon_distance'}}\n",
    "    # for the stattest_name value, you need to replace spaces by underscores\n",
    "    # the drift score must be of type float\n",
    "    # your code goes here\n",
    "    \n",
    "    return features, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cebf3c",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "Hier wiederum ein Lösungsvorschlag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bf96eb",
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataDriftPreset\n",
    "from evidently import ColumnMapping\n",
    "from loguru import logger\n",
    "\n",
    "\n",
    "def calculate_drift(df: pd.DataFrame, reference_df: pd.DataFrame,) -> tuple[tuple[str], tuple[float]]:\n",
    "\n",
    "    logger.info(f\"Received window of length {len(df)}\")\n",
    "    \n",
    "    # the dataframe generated from json has an index of dtype str, which we replace by an index of ints,\n",
    "    # or else evidently chokes\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # use a column mapping to make it easy for evidently to find the right metric\n",
    "    column_mapping = ColumnMapping()\n",
    "    column_mapping.categorical_features = ['cap-shape', 'gill-attachment', 'gill-color', 'stem-color']\n",
    "    column_mapping.numerical_features = [c for c in df.columns if c not in column_mapping.categorical_features]\n",
    "\n",
    "    # define and execute evidently standard drift report\n",
    "    data_drift_dataset_report = Report(metrics=[DataDriftPreset()])\n",
    "    data_drift_dataset_report.run(reference_data=reference_df, current_data=df, column_mapping=column_mapping)\n",
    "\n",
    "    # extract a list of features and calculated drift metrics from report\n",
    "    report_whole_output = data_drift_dataset_report.as_dict()\n",
    "    report_just_drift = report_whole_output[\"metrics\"][1][\"result\"][\"drift_by_columns\"]\n",
    "    metrics_dict = {}\n",
    "    for column_name, column_dict in report_just_drift.items():\n",
    "        metrics_dict[column_name] = {k:v for k, v in column_dict.items() if k in ['stattest_name', 'drift_score']}\n",
    "        metrics_dict[column_name]['stattest_name'] = metrics_dict[column_name]['stattest_name'].replace(' ', '_')\n",
    "        metrics_dict[column_name]['drift_score'] = float(metrics_dict[column_name]['drift_score'])\n",
    "    features, metrics = zip(*metrics_dict.items())\n",
    "    \n",
    "    return features, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261c89c5",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646a131d",
   "metadata": {},
   "source": [
    "## Statsd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc87313",
   "metadata": {},
   "source": [
    "Nun schreibst Du eine Funktion, welche über alle berechneten Feature/Metrik Paare loopt und für jedes Paar unter dem vorgegebenen Präfix ein *gauge* an statsd schickt. Wir verwendet die folgende [Statsd Python Bibliothek](https://statsd.readthedocs.io/en/latest/index.html).\n",
    "\n",
    "Als Dataset Name nimmst Du `mushroom` und als Version `v1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b103632",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "import statsd\n",
    "\n",
    "def report_drift_to_statsd(df: pd.DataFrame, reference_df: pd.DataFrame,\n",
    "                           statsd_client: statsd.client.udp.StatsClient) -> None:\n",
    "\n",
    "    # calculate metric per column\n",
    "    features, metrics = # your code goes here\n",
    "\n",
    "    # push to statsd\n",
    "    # your code goes here\n",
    "    prefix = ...\n",
    "    for ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3a5435",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "Wie der zu übergebende String genau auszusehen hat, findest Du im File `statsd_metrics-mapping.yml`, welches wir in der vorhergehenden Übung konfiguriert haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fe09bb",
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "import statsd\n",
    "\n",
    "def report_drift_to_statsd(df: pd.DataFrame, reference_df: pd.DataFrame, statsd_client: statsd.client.udp.StatsClient) -> None:\n",
    "    \n",
    "    # calculate metric per column\n",
    "    features, metrics = calculate_drift(df, reference_df)\n",
    "\n",
    "    # push to statsd\n",
    "    prefix = f\"drift_metrics.mushroom.v1\"\n",
    "    for f, m in zip(features, metrics):\n",
    "        statsd_client.gauge(f\"{prefix}.{f}.{m['stattest_name']}\", m['drift_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a213fe23",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105e1346",
   "metadata": {},
   "source": [
    "## Quix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2140d734",
   "metadata": {},
   "source": [
    "Wie in der Übung mit der Streaming Pipeline verwenden wir [Quix](https://www.quix.io/). Das Setup sieht wie folgt aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb254fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quixstreams import Application\n",
    "\n",
    "# create main quix object\n",
    "app = Application(\n",
    "    broker_address=\"message-broker:9092\",\n",
    ")\n",
    "\n",
    "# define topic and message format\n",
    "input_topic = app.topic(name=\"mushroom_inference_request\", value_deserializer=\"json\")\n",
    "\n",
    "# create a StreamingDataFrame\n",
    "sdf = app.dataframe(topic=input_topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b932cb2",
   "metadata": {},
   "source": [
    "Und nun wird es etwas kompliziert. Quix bietet bisher nur einfache Aggregationen auf Windows an. Sollen komplexere Aggregationen durchgeführt werden, muss mit zwei Callbacks (`initializer()` und `reducer()`) gearbeitet werden. Lies die entsprechende [Dokumentation](https://www.quix.io/docs/quix-streams/windowing.html#supported-aggregations) durch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dc986d",
   "metadata": {},
   "source": [
    "Unser `initializer()` wird genau einmal aufgerufen. Er erhält als Argument den Inhalt einer Kafka Event Notification als dict. Da wir mehrere solche dicts in einem dict sammeln wollen, fügen wir einen Index hinzu. Täten wir dies nicht, würde jede hinzugefügte Row die bisherige überschreiben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a5ed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializer(value: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Initialize the state for aggregation when a new window starts.\n",
    "\n",
    "    It will prime the aggregation when the first record arrives \n",
    "    in the window.\n",
    "    \"\"\"\n",
    "    \n",
    "    # add a string index to the dict to get something like this\n",
    "    # we need this second level when combining multiple rows in\n",
    "    # the reducer, or else we just overwrite the same value\n",
    "    # again and again\n",
    "    \n",
    "    \"\"\"\n",
    "    {0: {'cap-diameter': 3.0,\n",
    "      'cap-shape': 3.0,\n",
    "      'gill-attachment': 5.0,\n",
    "      'gill-color': 2.0,\n",
    "      'stem-height': 0.7591098099,\n",
    "      'stem-width': 1397.0,\n",
    "      'stem-color': 9.0,\n",
    "      'season': 0.9545582517}}\n",
    "    \"\"\"\n",
    "    \n",
    "    return {str(k):v for k,v in enumerate([value])}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a3ed75",
   "metadata": {},
   "source": [
    "Unser `reducer()` macht fast dasselbe. Er fügt die neu erhaltene message den bisherigen hinzu. Das geht einfach, wenn wir zuerst den Index entfernen, und dann wieder einen inkrementellen Index hinzufügen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb515c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reducer(aggregated: dict, value: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Called on every row but the first\n",
    "\n",
    "    Reducer always receives two arguments:\n",
    "    - previously aggregated value (the \"aggregated\" argument)\n",
    "    - current value (the \"value\")\n",
    "    It combines them into a new aggregated value and returns it.\n",
    "    This aggregated value will be also returned as a result of the window.\n",
    "    \"\"\"\n",
    "\n",
    "    # first add old and new (without their respective index)\n",
    "    list_of_dicts = [value] + list(aggregated.values())\n",
    "    \n",
    "    # then readd an incremental index\n",
    "    return {str(k):v for k,v in enumerate(list_of_dicts)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66056ef",
   "metadata": {},
   "source": [
    "Instanziere nun noch den statsd client, definiere den Streaming Dataframe und starte den Streaming Prozess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e4705f",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "statsd_client = statsd.StatsClient('statsd', 8125)\n",
    "\n",
    "sdf = (\n",
    "    # quix lacks the functionality to define a window of a fixed size, which would be appropriate here\n",
    "    # so instead as a crutch, we use a tumbling window, which works but is a bit weird\n",
    "    # don't make it too short, it should be long enough that reducer is called at least once\n",
    "    \n",
    "    # your code here (tumbling window with window size 10 seconds)\n",
    "\n",
    "    # create a \"reduce\" aggregation with \"reducer\" and \"initializer\" functions\n",
    "    # this is the quix way to define arbitrary aggregations (standard aggregations have their convenience functions)\n",
    "    \n",
    "    # your code here (add the reducer and initializer callbacks)\n",
    "\n",
    "    # emit results only for closed windows\n",
    "    \n",
    "    # your code here\n",
    "\n",
    "    # now calculate drift statistics on full windows\n",
    "    .apply(lambda m: report_drift_to_statsd(pd.DataFrame(m[\"value\"]).T, reference_df, statsd_client))\n",
    ")\n",
    "\n",
    "app.run(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f81608",
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "statsd_client = statsd.StatsClient('statsd', 8125)\n",
    "\n",
    "sdf = (\n",
    "    # quix lacks the functionality to define a window of a fixed size, which would be appropriate here\n",
    "    # so instead as a crutch, we use a tumbling window, which works but is a bit weird\n",
    "    # don't make it too short, it should be long enough that reducer is called at least once\n",
    "    sdf.tumbling_window(duration_ms=timedelta(seconds=10))\n",
    "\n",
    "    # create a \"reduce\" aggregation with \"reducer\" and \"initializer\" functions\n",
    "    # this is the quix way to define arbitrary aggregations (standard aggregations have their convenience functions)\n",
    "    .reduce(reducer=reducer, initializer=initializer)\n",
    "\n",
    "    # emit results only for closed windows\n",
    "    .final()\n",
    "\n",
    "    # now calculate drift statistics on full windows\n",
    "    .apply(lambda m: report_drift_to_statsd(pd.DataFrame(m[\"value\"]).T, reference_df, statsd_client))\n",
    ")\n",
    "\n",
    "app.run(sdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39191d91",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71547189",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eac26a",
   "metadata": {},
   "source": [
    "Du kannst nun obigen Code für die Drift Detection Pipeline ausführen. Entweder erstellst du analog dem Data Generator ein Skript, oder du führst in direkt aus einem Notebook aus.\n",
    "\n",
    "Starte den Code der Drift Pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf9ee75",
   "metadata": {},
   "source": [
    "Nun starte den Datengenerator. Gib gleich ein wenig Gas, damit die Drift Pipeline auch genug Daten hat, um aussagekräftige Vergleiche zu machen.\n",
    "\n",
    "````\n",
    "docker compose run --rm --name=datagen --entrypoint=python3 development_env mushroom_datagen.py -b 10 -s 100 -r 5````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d3533d",
   "metadata": {},
   "source": [
    "Überprüfe, ob\n",
    " * Die Drift Pipeline Windows verschiedener Grösse erkennt (Log Meldungen in etwa *Received window of length 152*)\n",
    " * Im [Statsd](http://localhost:9102/metrics) Updates sichtbar sind\n",
    " * In [Prometheus](http://127.0.0.1:9090/graph?g0.expr=drift_metrics&g0.tab=1&g0.display_mode=lines&g0.show_exemplars=0&g0.range_input=1h) Updates sichtbar sind\n",
    " * In [Grafana](http://localhost:3000/) Datenpunkte ankommen (stelle oben rechts das Anzeige-Intervall auf *Last 5 Minutes*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cee920",
   "metadata": {},
   "source": [
    "Wenn alles klappt, **stoppe den Datengenerator wieder**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5925f640",
   "metadata": {},
   "source": [
    "## Drift Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eb1ef4",
   "metadata": {},
   "source": [
    "Nun erweitern wir den Datengenerator, damit er für eine Spalte einen Drift einfügen kann. Der Einfachheit halber hardcoden wir die Art des Driftes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51409bab",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "Füge den Datengenerator ein weiteres Kommandozeilenargument hinzu vom Typ `int` mit dem switch `-d` für \"drift_factor\" und default 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c8eb97",
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "parser.add_argument(\n",
    "    \"-d\",\n",
    "    \"--drift_factor\",\n",
    "    type=int,\n",
    "    help=\"Start factor for simulating drift\",\n",
    "    default=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ef2c0e",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39606b1d",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "Ziehe das Argument durch alle notwendigen Funktionsaufrufe und Funktionsheader durch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fea2f8",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "Anpassungen im\n",
    " * `run()` Aufruf\n",
    " * in der `run()` Deklaration\n",
    " * im `generate_event()` Aufruf\n",
    " * in der `generate_event()` Deklaration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcc3045",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cf5e6e",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "Nun multipliziere in der Funktion `generate_event()` oberhalb des return Statements den Wert der Spalte `season` mit dem `drift`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12224083",
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "new_row['season'] = new_row['season']*drift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e43f62",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc837a35",
   "metadata": {},
   "source": [
    "Lösche alle bereits gemachten Meldungen und Messungen.\n",
    " * stoppe den Datengenerator und die Drift Pipeline\n",
    " * lösche in der [Redpanda Konsole](http://127.0.0.1:8085/topics) alle Topics\n",
    " * **speichere deine offenen Notebooks**\n",
    " * stoppe alle Services (docker compose down)\n",
    " * lösche den Ordner `state`, welchen die Drift Pipeline automatisch erstellt (im Verzeichnis, wo auch das Notebook bzw. Skript der Drift Pipeline liegt)\n",
    " * lösche das File `grafana_work/data/grafana.db` \n",
    " * starte die Services wieder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d99baf",
   "metadata": {},
   "source": [
    "Baue dir in Grafana ein neues Dashboard, welches dir den Drift anzeigt. Als einfache Variante kannst du zwei Liniendiagramme machen, einmal für eine Spalte ohne Drift, und einmal für eine Spalte mit Drift."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780cda93",
   "metadata": {},
   "source": [
    "Starte nun die Drift Detection Pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0e0d8e",
   "metadata": {},
   "source": [
    "Dann generiere Daten, zuerst etwa eine Minute lang ohne Drift:\n",
    "\n",
    "````\n",
    "docker compose run --rm --name=datagen --entrypoint=python3 development_env mushroom_datagen.py -b 10 -s 100 -r 5\n",
    "````\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d17638c",
   "metadata": {},
   "source": [
    "Schaue Dir das Grafana Dashboard an."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a23498",
   "metadata": {},
   "source": [
    "Nun füge Drift hinzu:\n",
    "````\n",
    "docker compose run --rm --name=datagen --entrypoint=python3 development_env mushroom_datagen.py -b 10 -s 100 -r 5 -d 2\n",
    "````\n",
    "\n",
    "Lasse dies wieder etwa eine Minute laufen, dann kannst du stoppen und den Drift auf 3 erhöhen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24689fce",
   "metadata": {},
   "source": [
    "Du solltest nun in Grafana beobachten können, wie die der Drift für die Spalte `season` zunimmt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f3698f",
   "metadata": {},
   "source": [
    "## Wrapup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0193f7a0",
   "metadata": {},
   "source": [
    "Du hast in dieser Übung eine Stream Processing Pipeline gebaut, welche Inferenz-Requests für unser Mushroom Modell auf Datendrift überwacht und die Ergebnisse an unsere Monitoring Infrastruktur meldet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5811ee",
   "metadata": {},
   "source": [
    "Dabei haben wir wiederum auch ein paar Abkürzungen genommen, was im Rahmen eines Kurses zwar vertretbar ist, deren wir uns daber auch bewusst sein sollten:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5b57ae",
   "metadata": {},
   "source": [
    "* Wir haben Evidently einen ganzen Report berechnen lassen, anstatt nur die Metrik, welche wir brauchen\n",
    "* Wir haben uns nicht um Skalierbarkeit gekümmert. Mit unserem Aufbau und Quix ist die Pipeline einfach skalierbar\n",
    "* Unser Meldungsformat war sehr einfach und ohne jegliche Metadaten\n",
    "* Unser Meldungsformat war ein einfaches json, ohne Schema und Validierung\n",
    "* Einige Dinge haben wir hartkodiert bzw. nicht sauber entkoppelt (z.B. Feature Typen, Topic)\n",
    "* Keine Tests, kein sauberes Error Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2700bb70",
   "metadata": {},
   "source": [
    "Und inbesondere"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3208c45",
   "metadata": {},
   "source": [
    "Wir prüfen nur die Rohdaten auf Drift. Es ist selbstverständlich auch empfohlen, Features zu prüfen. Dies wird wichtiger, sobald die Anzahl von Features und Modellen zunimmt, undnur mit einem Feature Store sinnvoll umsetzbar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b632b78",
   "metadata": {},
   "source": [
    "**Bitte quittiere wiederum auf [Mentimeter](https://www.menti.com/alaxbnek73eu), dass du mit der Übung durch bist**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
