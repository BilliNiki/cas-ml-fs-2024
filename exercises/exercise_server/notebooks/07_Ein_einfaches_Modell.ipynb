{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb1a9be2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Achtung:</b> Der hier angezeigt Code kann nicht direkt im Exercise Server ausgeführt werden. Der Code fuktioniert nur im <a href=\"http://localhost:8080/lab\">Jupyter Lab der Development Environment</a>.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0058ee",
   "metadata": {},
   "source": [
    "# Ein einfaches ML Modell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834490dd",
   "metadata": {},
   "source": [
    "In dieser Übung wird als Grundlage für die nachfolgenden Übungen ein einfaches Machine Learning Modell trainiert. Der Vorgang simuliert die Arbeit der *Data Scientisten*, welche Daten analysieren und Modelle bauen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584622d6",
   "metadata": {},
   "source": [
    "# Vorbereitung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eec21d",
   "metadata": {},
   "source": [
    "## Notebook für den Code erstellen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d4e5a0",
   "metadata": {},
   "source": [
    "Erstelle als erstes in der Development Environment ein neues, leeres Jupyter Notebook, in welchem du die nachfolgenden Aufgaben lösen kannst. Nütze auch die Markdown-Funkionalität, um deine Gedanken zu notieren und um zu dokumentieren!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b64cea",
   "metadata": {},
   "source": [
    "Nenne das Notebook `01-Simple_Model.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dc1ad8",
   "metadata": {},
   "source": [
    "## Trainingsdaten downloaden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea87e5ab",
   "metadata": {},
   "source": [
    "Zur Vorbereitung müssen Trainingsdaten im Object Store platziert werden. Führe dazu die folgenden Schritte durch, um das File downzuloaden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d02a1e1",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "Lade [dieses Zipfile](https://www.kaggle.com/api/v1/datasets/download/prishasawhney/mushroom-dataset?datasetVersionNumber=1) herunter, entpacke es, und lies daraus das file 'mushroom_cleaned.csv' in einen pandas dataframe ein.\n",
    "\n",
    "Hint: Du kannst dies mit [requests](https://docs.python-requests.org/en/latest/index.html), [zipfile](https://docs.python.org/3/library/zipfile.html) und [io](https://docs.python.org/3/library/io.html) direkt machen. Oder Du holst das File mit deinem Browser und uploadest das CSV ins Jupyter.\n",
    "\n",
    "**Wichtig**: Lies das File direkt mit read_csv(), gib dabei keine Optionen an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefd5a17",
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "import requests, zipfile, io\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.kaggle.com/api/v1/datasets/download/prishasawhney/mushroom-dataset?datasetVersionNumber=1'\n",
    "r = requests.get(url)\n",
    "\n",
    "with zipfile.ZipFile(io.BytesIO(r.content)) as z:\n",
    "    with z.open('mushroom_cleaned.csv') as f:\n",
    "        df = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5235a9",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817d62db",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "Erstelle nun einen Bucket mit Name `traindata` im objectstore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45870ff",
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "import s3fs\n",
    "\n",
    "s3 = s3fs.S3FileSystem()\n",
    "s3.mkdir(\"traindata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddccadc1",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01938f5c",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "Speichere schliesslich das csv File als Parquet unter dem Namen 'traindata/train_raw.parquet'.\n",
    "\n",
    "Hint: Wenn du dies direkt mit pandas machst, musst du das Argument `storage_options={\"anon\": False}` angeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408be47f",
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "df.to_parquet('s3://traindata/train_raw.parquet', storage_options={\"anon\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775ec602",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdd83a2",
   "metadata": {},
   "source": [
    "# Übungen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dffc2fe",
   "metadata": {},
   "source": [
    "## Das Mushroom Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a5c671",
   "metadata": {},
   "source": [
    "Das Mushroom Dataset, welches wir für einige Übungen verwenden, ist gedacht, um Pilze anhand verschiedener Merkmale in die beiden Klassen *essbar* und *giftig* einzuteilen. Es kommt in tabellarischer Form daher mit 8 Features und einem Label.\n",
    "\n",
    "Das originale Datenset kommt aus dem [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/848/secondary+mushroom+dataset). Dort gibt eine Beschreibung, was die Spalten bedeuten. Für uns ist dies heute jedoch sekundär.\n",
    "\n",
    "Die Version, welche auf Kaggle bereitgestellt wurde, ist gesäubert und enthält weniger Spalten als das Original. \n",
    "\n",
    "Das Label enthält zwei Werte, 0 für *essbar* und 1 für *giftig*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7944b73c",
   "metadata": {},
   "source": [
    "## Trainingsdaten aus Object Store lesen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882496fc",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "Verwende Pandas, um das gerade gespeicherte Parquet-File in einen Dataframe zu lesen (nach dem Ausführen von obigem Code wäre das natürlich nicht notwendig, da der DataFrame schon im Memory ist. Wir tun es aber trotzdem)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37559dc",
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet('s3://traindata/train_raw.parquet', storage_options={\"anon\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05d767f",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96618bab",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70acaf16",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "Schaue Dir nun den DataFrame an, um ein Gefühl für die Daten zu bekommen, zum Beispiel\n",
    " * Erste paar Zeilen\n",
    " * Anzahl Spalten und Zeilen\n",
    " * Datentypen\n",
    " * Anzahl unterschiedliche Werte pro Spalte\n",
    " * NaNs\n",
    " * Mögliche Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead3618d",
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3194e9",
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e51536",
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b82dad",
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16635397",
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "df.isna().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabc92ff",
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec05dfa4",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a62b78",
   "metadata": {},
   "source": [
    "Natürlich wäre hier noch viel mehr möglich, wir kürzen aber ab, da dies ein Kurs für MLOps und nicht für Modelling ist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fc3085",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc416013",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "Es ist nicht notwendig, neue Features zu engineeren. Wenn du möchtest, kannst du dies natürlich tun.\n",
    "\n",
    "Wir bauen  zwei Listen `categoricals` und `numericals`, welche je die Spaltennamen der kategorischen und der numerischen Spalten enthalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2155d2f9",
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "categoricals = ['cap-shape', 'gill-attachment', 'gill-color', 'stem-color']\n",
    "numericals = [c for c in df.drop('class', axis='columns').columns if c not in categoricals]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3770134",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d4dbd8",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "Konvertiere alle Spalten in den Datentyp `float`. Dies wird später helfen, wenn wir mit MLFlow arbeiten, denn MLFlow bekundet Mühe mit Spalten der Typen `int` oder `categorical`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4bd0e3",
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    df[col] = df[col].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa94e22",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b6bb19",
   "metadata": {},
   "source": [
    "## Finales Test Set vorbereiten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fb7a5f",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "Mit der Funktion [train_test_split von sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) teilen wir das Datenset auf in Trainings- und Testset `X_train`, `X_test`, `y_train`, `y_test` (`random_state=42`, ansonsten default-Parameter belassen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06aab6eb",
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('class', axis='columns'), df['class'], random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b834ef16",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd0df79",
   "metadata": {},
   "source": [
    "## Ein einfaches Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4d71cc",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "Nun kannst du ein einfaches Modell mit sklearn definieren. Varianten gibt es viele, es kommt für den Kurs nicht darauf an, welches Modell du wählst und wie gut es ist. Der folgende Lösungsvorschlag ist nur eine Möglichkeit von vielen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97211094",
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"numerical\", StandardScaler(), numericals),\n",
    "        (\"categorical\", OneHotEncoder(sparse_output=False), categoricals),\n",
    "    ],\n",
    ")\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "pipeline = make_pipeline(preprocessor, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32411e26",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096ee38c",
   "metadata": {},
   "source": [
    "## Modell evaluieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98687e13",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "Während der Modell-Entwicklung können wir einfach mit der Funtion `cross_val_score` evaluieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4649ad27",
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "n_folds = 10\n",
    "scores = cross_val_score(pipeline, X_train, y_train, cv=n_folds)\n",
    "f\"{pipeline.steps[-1][-1]} has an accuracy of {scores.mean():0.2f} \" +\n",
    "f\"(standard deviation {scores.std():0.2f}) over all {n_folds} folds\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2d4c94",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8c3ba3",
   "metadata": {},
   "source": [
    "## Finale Score prüfen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b06800",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "Am Schlusss prüfen wir unser Model gegen das Test set, um zu die Score zu evaluieren (denn in langen Modellierungsphasen kann es vorkommen, dass wir das Validationset overfitten)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd58cbc9",
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(pipeline, X_test, y_test)\n",
    "\n",
    "print(f\"{pipeline.steps[-1][-1]} has an accuracy of {accuracy_score(y_test, y_pred):0.2f}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29febe4b",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37d67c2",
   "metadata": {},
   "source": [
    "## Modell mit allen Daten trainieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974835c8",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "Zum Schluss trainieren wir das Modell noch einmal mit allen zur Verfügung stehenden Daten, um auch das letzte Quäntchen Performance rauszuquetschen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2a86ae",
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "pipeline.fit(df.drop('class', axis='columns'), df['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c895a949",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9be261",
   "metadata": {},
   "source": [
    "**Bitte quittiere wiederum auf [Mentimeter](https://www.menti.com/alaxbnek73eu), dass du mit der Übung durch bist**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
